{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RRbStil_qkQc",
        "kCENjOq6owDd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 2"
      ],
      "metadata": {
        "id": "tFaf7VErZ1Bf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "I3g3k3W-qfAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing packages"
      ],
      "metadata": {
        "id": "6vsESFZylO6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests PyPDF2 gdown\n",
        "!pip install 'markitdown[pdf]'\n",
        "!pip install langchain_mcp_adapters langchain_google_genai langchain-openai"
      ],
      "metadata": {
        "id": "Hrdfpmv9nMpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4122b9f-b098-497d-9629-2b3b430ad182",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.24.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: markitdown[pdf] in /usr/local/lib/python3.12/dist-packages (0.1.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (4.13.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (3.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.7.1)\n",
            "Requirement already satisfied: magika~=0.6.1 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.6.3)\n",
            "Requirement already satisfied: markdownify in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (1.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (2.32.4)\n",
            "Requirement already satisfied: pdfminer-six>=20251230 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (20251230)\n",
            "Requirement already satisfied: pdfplumber>=0.11.9 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.11.9)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (8.3.1)\n",
            "Requirement already satisfied: onnxruntime>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (1.24.2)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (2.0.2)\n",
            "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer-six>=20251230->markitdown[pdf]) (43.0.3)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber>=0.11.9->markitdown[pdf]) (11.3.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber>=0.11.9->markitdown[pdf]) (5.5.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (4.15.0)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify->markitdown[pdf]) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2026.1.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer-six>=20251230->markitdown[pdf]) (2.0.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (25.12.19)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (26.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (5.29.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20251230->markitdown[pdf]) (3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.3.0)\n",
            "Requirement already satisfied: langchain_mcp_adapters in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.12/dist-packages (4.2.1)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.1.10)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.2.13)\n",
            "Requirement already satisfied: mcp>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.26.0)\n",
            "Requirement already satisfied: typing-extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (4.15.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.63.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (2.12.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.21.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.47.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (9.1.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.3.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.7.3)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (6.0.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.14.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.3)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (4.26.0)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (2.13.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.11.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.0.22)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (3.2.0)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.52.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.41.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (4.67.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (2.41.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.11)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.30.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp>=1.9.2->langchain_mcp_adapters) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (43.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.5.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp>=1.9.2->langchain_mcp_adapters) (8.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.6.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `VERTEX_API_KEY`.\n",
        "\n",
        "\n",
        "1.   Look for the key icon on the left panel of your colab.\n",
        "2.   Under `Name`, create `VERTEX_API_KEY`.\n",
        "3. Copy your key to `Value`.\n",
        "\n",
        "If you cannot use VERTEX_API_KEY, you can use deepseek models via `DEEPSEEK_API_KEY`. It does not affect your score.\n",
        "\n"
      ],
      "metadata": {
        "id": "BUav-7KdaY_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_VERTEX_API_KEY = userdata.get('VERTEX_API_KEY')\n",
        "# DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')"
      ],
      "metadata": {
        "id": "ueILmCPHci9v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download sample CVs"
      ],
      "metadata": {
        "id": "RRbStil_qkQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading sample_cv.pdf\n",
        "The codes below download the sample CV\n"
      ],
      "metadata": {
        "id": "kCENjOq6owDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "\n",
        "folder_id = \"1adYKq7gSSczFP3iikfA8Er-HSZP6VM7D\"\n",
        "folder_url = f\"https://drive.google.com/drive/folders/{folder_id}\"\n",
        "\n",
        "output_dir = \"downloaded_cvs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "gdown.download_folder(\n",
        "    url=folder_url,\n",
        "    output=output_dir,\n",
        "    quiet=False,\n",
        "    use_cookies=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kCCp8DwPF4L",
        "outputId": "d0c208bb-8f0b-46bc-afea-7ba39db875a3",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp CV_1.pdf\n",
            "Processing file 16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs CV_2.pdf\n",
            "Processing file 15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr CV_3.pdf\n",
            "Processing file 1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk CV_4.pdf\n",
            "Processing file 1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C CV_5.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp\n",
            "To: /content/downloaded_cvs/CV_1.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147k/147k [00:00<00:00, 15.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs\n",
            "To: /content/downloaded_cvs/CV_2.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75.1k/75.1k [00:00<00:00, 10.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr\n",
            "To: /content/downloaded_cvs/CV_3.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72.0k/72.0k [00:00<00:00, 10.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk\n",
            "To: /content/downloaded_cvs/CV_4.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73.3k/73.3k [00:00<00:00, 59.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C\n",
            "To: /content/downloaded_cvs/CV_5.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.9k/97.9k [00:00<00:00, 17.7MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['downloaded_cvs/CV_1.pdf',\n",
              " 'downloaded_cvs/CV_2.pdf',\n",
              " 'downloaded_cvs/CV_3.pdf',\n",
              " 'downloaded_cvs/CV_4.pdf',\n",
              " 'downloaded_cvs/CV_5.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to our MCP server\n",
        "\n",
        "Documentation about MCP: https://modelcontextprotocol.io/docs/getting-started/intro.\n",
        "\n",
        "Using MCP servers in Langchain https://docs.langchain.com/oss/python/langchain/mcp."
      ],
      "metadata": {
        "id": "VA2GvPWTQFt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check which tools that the MCP server provide"
      ],
      "metadata": {
        "id": "5mbkH9xHXfmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "mcp_tools = asyncio.run(client.get_tools())\n",
        "for tool in mcp_tools:\n",
        "    print(tool.name)\n",
        "    print(tool.description)\n",
        "    print(tool.args)\n",
        "    print(\"\\n\\n------------------------------------------------------\\n\\n\")"
      ],
      "metadata": {
        "id": "6h0311KbN9A3",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a94d8eaf-cf1f-4168-81b2-e399f8c376dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "search_facebook_users\n",
            "Search for Facebook users by display name (supports partial and fuzzy matching).\n",
            "\n",
            "Args:\n",
            "    q: Search query string (case-insensitive, matches any part of display name)\n",
            "       Examples: \"John\", \"john smith\", \"Smith\"\n",
            "    limit: Maximum number of results to return (default: 20, max: 20)\n",
            "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
            "\n",
            "Returns:\n",
            "    List of user dictionaries, each containing:\n",
            "    - id (int): Unique Facebook user ID for use with get_facebook_profile()\n",
            "    - display_name (str): User's Facebook display name (may differ from legal name)\n",
            "    - city (str): Current city of residence\n",
            "    - country (str): Country of residence\n",
            "    - match_type (str): \"exact\" or \"fuzzy\" (indicates search method used)\n",
            "    \n",
            "    Returns empty list [] if no matches found.\n",
            "\n",
            "Example:\n",
            "    search_facebook_users(\"Alex Chan\", limit=5)\n",
            "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"exact\"}]\n",
            "    \n",
            "    search_facebook_users(\"Alx Chn\", limit=5)  # Typo - uses fuzzy matching\n",
            "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"fuzzy\"}]\n",
            "\n",
            "Use case:\n",
            "    First step in CV verification - find candidate's Facebook profile to cross-check\n",
            "    personal information, location, and social connections. Handles typos and variations.\n",
            "{'q': {'type': 'string'}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_facebook_profile\n",
            "Retrieve complete Facebook profile including personal info, bio, relationships, and activity.\n",
            "\n",
            "Args:\n",
            "    user_id: Facebook user ID obtained from search_facebook_users()\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - id (int): Facebook user ID\n",
            "    - display_name (str): Public display name (may be nickname)\n",
            "    - original_name (str): Original/legal name from LinkedIn\n",
            "    - city (str): Current city\n",
            "    - country (str): Current country\n",
            "    - hometown (str|None): City/region where user grew up\n",
            "    - bio (str): Personal biography/interests\n",
            "    - status (str|None): Relationship status (Single, Married, etc.)\n",
            "    - education (str|None): Highest education level\n",
            "    - current_job (str|None): Current job title\n",
            "    - current_company (str|None): Current employer\n",
            "    - interests (str): Comma-separated hobbies/interests\n",
            "    - friends (List[int]): List of friend user IDs\n",
            "    - posts (List[dict]): Recent posts with id and content\n",
            "    \n",
            "    Returns {\"error\": \"User not found\"} if user_id is invalid.\n",
            "\n",
            "Example:\n",
            "    get_facebook_profile(123)\n",
            "    â†’ {\n",
            "        \"id\": 123,\n",
            "        \"display_name\": \"Sam Chan\",\n",
            "        \"original_name\": \"Alex Chan\",\n",
            "        \"city\": \"Hong Kong\",\n",
            "        \"hometown\": \"Kowloon\",\n",
            "        \"bio\": \"Software professional | Photography enthusiast\",\n",
            "        \"status\": \"Married\",\n",
            "        \"current_job\": \"Senior Engineer\",\n",
            "        \"current_company\": \"Google\",\n",
            "        \"friends\": [124, 125, 126],\n",
            "        \"posts\": [{\"id\": 1, \"content\": \"Excited to announce...\"}]\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Verify candidate's personal details, check for name discrepancies,\n",
            "    validate current employment, and assess social connections.\n",
            "{'user_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_facebook_mutual_friends\n",
            "Find mutual friends between two Facebook users (useful for verifying social connections).\n",
            "\n",
            "Args:\n",
            "    user_id_1: First Facebook user ID\n",
            "    user_id_2: Second Facebook user ID\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - user_1_id (int): First user's ID\n",
            "    - user_2_id (int): Second user's ID\n",
            "    - mutual_friends (List[int]): List of shared friend IDs\n",
            "    - mutual_count (int): Number of mutual friends\n",
            "    \n",
            "    Returns {\"error\": \"...\"} if either user not found.\n",
            "\n",
            "Example:\n",
            "    get_facebook_mutual_friends(123, 456)\n",
            "    â†’ {\"user_1_id\": 123, \"user_2_id\": 456, \"mutual_friends\": [789, 790], \"mutual_count\": 2}\n",
            "\n",
            "Use case:\n",
            "    Verify professional or personal relationships claimed in CV/references.\n",
            "{'user_id_1': {'type': 'integer'}, 'user_id_2': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "search_linkedin_people\n",
            "Search LinkedIn profiles by name, headline, skills, or keywords with optional filters.\n",
            "\n",
            "Args:\n",
            "    q: Search query (matches name, headline, summary, or skill names)\n",
            "       Examples: \"software engineer\", \"Python\", \"data scientist\", \"Alex Chan\"\n",
            "    location: Filter by location (optional, case-insensitive, matches city OR country)\n",
            "              Examples: \"Hong Kong\", \"Singapore\", \"China\", \"USA\", \"New York\"\n",
            "    industry: Filter by industry (optional, case-insensitive)\n",
            "              Examples: \"Software\", \"Finance\", \"AI\", \"Consulting\"\n",
            "    limit: Maximum results to return (default: 20, max: 20)\n",
            "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
            "\n",
            "Returns:\n",
            "    List of profile dictionaries, each containing:\n",
            "    - id (int): LinkedIn profile ID for use with get_linkedin_profile()\n",
            "    - name (str): Full name\n",
            "    - headline (str): Professional headline/title\n",
            "    - industry (str): Industry sector\n",
            "    - location (str): \"City, Country\" format\n",
            "    - years_experience (int): Total years of work experience\n",
            "    - match_type (str): \"exact\" or \"fuzzy\"\n",
            "    \n",
            "    Returns empty list [] if no matches found.\n",
            "\n",
            "Example:\n",
            "    search_linkedin_people(\"Python developer\", location=\"Hong Kong\", limit=5)\n",
            "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
            "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"exact\"}]\n",
            "    \n",
            "    search_linkedin_people(\"Pythn develper\", location=\"Hong Kong\", limit=5)  # Typo\n",
            "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
            "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"fuzzy\"}]\n",
            "\n",
            "Use case:\n",
            "    Find candidate's LinkedIn profile using name, skills, or job title from CV.\n",
            "    Use location filter to narrow down results when common names exist. Handles typos.\n",
            "{'q': {'type': 'string'}, 'location': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'industry': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_linkedin_profile\n",
            "Retrieve complete LinkedIn professional profile including work history, education, and skills.\n",
            "\n",
            "Args:\n",
            "    person_id: LinkedIn profile ID obtained from search_linkedin_people()\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - id (int): LinkedIn profile ID\n",
            "    - name (str): Full name\n",
            "    - headline (str): Professional headline\n",
            "    - city (str): Current city\n",
            "    - country (str): Current country\n",
            "    - industry (str): Primary industry\n",
            "    - status (str): Employment status (employed, open_to_work, hiring, student)\n",
            "    - years_experience (int): Total years of professional experience\n",
            "    - summary (str): Professional summary/bio\n",
            "    \n",
            "    - skills (List[dict]): Each containing:\n",
            "        * name (str): Skill name (e.g., \"Python\", \"Machine Learning\")\n",
            "        * proficiency (int): Skill level 1-5 (1=beginner, 5=expert)\n",
            "    \n",
            "    - experience (List[dict]): Work history, each containing:\n",
            "        * company (str): Employer name\n",
            "        * title (str): Job title\n",
            "        * seniority (str): Level (junior, mid, senior)\n",
            "        * start_year (int): Employment start year\n",
            "        * end_year (int|None): Employment end year (None if current)\n",
            "        * is_current (bool): Whether currently employed here\n",
            "    \n",
            "    - education (List[dict]): Academic history, each containing:\n",
            "        * school (str): Institution name\n",
            "        * degree (str): Degree type (BSc, MSc, MBA, PhD)\n",
            "        * field (str): Field of study\n",
            "        * start_year (int): Start year\n",
            "        * end_year (int): Graduation year\n",
            "    \n",
            "    Returns {\"error\": \"Profile not found\"} if person_id is invalid.\n",
            "\n",
            "Example:\n",
            "    get_linkedin_profile(456)\n",
            "    â†’ {\n",
            "        \"id\": 456,\n",
            "        \"name\": \"Alex Chan\",\n",
            "        \"headline\": \"Senior Software Engineer\",\n",
            "        \"years_experience\": 8,\n",
            "        \"skills\": [\n",
            "            {\"name\": \"Python\", \"proficiency\": 5},\n",
            "            {\"name\": \"Docker\", \"proficiency\": 4}\n",
            "        ],\n",
            "        \"experience\": [\n",
            "            {\n",
            "                \"company\": \"Google\",\n",
            "                \"title\": \"Senior Engineer\",\n",
            "                \"seniority\": \"senior\",\n",
            "                \"start_year\": 2020,\n",
            "                \"end_year\": None,\n",
            "                \"is_current\": True\n",
            "            }\n",
            "        ],\n",
            "        \"education\": [\n",
            "            {\n",
            "                \"school\": \"HKUST\",\n",
            "                \"degree\": \"BSc\",\n",
            "                \"field\": \"Computer Science\",\n",
            "                \"start_year\": 2010,\n",
            "                \"end_year\": 2014\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Primary tool for CV verification - compare claimed experience, education,\n",
            "    skills, and employment dates against LinkedIn ground truth.\n",
            "{'person_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_linkedin_interactions\n",
            "Retrieve LinkedIn engagement data showing who has interacted with a person's content.\n",
            "\n",
            "Args:\n",
            "    person_id: LinkedIn profile ID\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - profile_id (int): The person's LinkedIn ID\n",
            "    - post_count (int): Number of posts made\n",
            "    - total_likes (int): Total likes received across all posts\n",
            "    - liked_by (List[int]): Unique profile IDs who have liked this person's posts\n",
            "    - engagement_score (float): Likes per post ratio\n",
            "    \n",
            "    Returns {\"profile_id\": X, \"liked_by\": [], ...} if person has no posts.\n",
            "\n",
            "Example:\n",
            "    get_linkedin_interactions(456)\n",
            "    â†’ {\n",
            "        \"profile_id\": 456,\n",
            "        \"post_count\": 10,\n",
            "        \"total_likes\": 150,\n",
            "        \"liked_by\": [123, 124, 125],\n",
            "        \"engagement_score\": 15.0\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Assess professional network strength and content engagement.\n",
            "    Verify connections to claimed colleagues or industry peers.\n",
            "{'person_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "#  Load and display all CV PDFs in order\n",
        "# =====================================================\n",
        "import os\n",
        "from markitdown import MarkItDown\n",
        "\n",
        "cv_dir = \"downloaded_cvs\"\n",
        "\n",
        "# Initialize MarkItDown\n",
        "md = MarkItDown(enable_plugins=False)\n",
        "\n",
        "# Collect and sort PDFs numerically\n",
        "pdf_files = sorted(\n",
        "    [f for f in os.listdir(cv_dir) if f.lower().endswith(\".pdf\")],\n",
        "    key=lambda x: int(\"\".join(filter(str.isdigit, x)))  # CV_1.pdf â†’ 1\n",
        ")\n",
        "\n",
        "all_cvs = []\n",
        "\n",
        "for pdf_name in pdf_files:\n",
        "    pdf_path = os.path.join(cv_dir, pdf_name)\n",
        "    result = md.convert(pdf_path)\n",
        "\n",
        "    all_cvs.append({\n",
        "        \"file\": pdf_name,\n",
        "        \"text\": result.text_content\n",
        "    })\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"ðŸ“„ {pdf_name}\")\n",
        "    print(\"=\" * 80)\n",
        "    print(result.text_content)\n",
        "    print(\"\\n\\n\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "e4M_4HG-VjU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76801cfe-a0f6-4165-a1a2-ddbd1af567d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "ðŸ“„ CV_1.pdf\n",
            "================================================================================\n",
            "|     |     |     |     | John         |           | Smith        |                   |     |     |\n",
            "| --- | --- | --- | --- | ------------ | --------- | ------------ | ----------------- | --- | --- |\n",
            "|     |     |     |     | Marketing    |           | Professional |                   |     |     |\n",
            "|     |     |     |     | + Singapore, | Singapore |              | (cid:209) Kowloon |     |     |\n",
            "Experience\n",
            "|                |                  |     |          |                     |              |            |     | 2020 â€“ | Present |\n",
            "| -------------- | ---------------- | --- | -------- | ------------------- | ------------ | ---------- | --- | ------ | ------- |\n",
            "| Engineer,      | ByteDance        |     |          |                     |              |            |     |        |         |\n",
            "| â€¢ Worked       | in a fast-paced, |     | global   | technology          | environment. |            |     |        |         |\n",
            "| â€¢ Collaborated | across           |     | teams to | support large-scale |              | platforms. |     |        |         |\n",
            "â€¢ Applied analytical and problem-solving skills in production systems.\n",
            "Education\n",
            "| McGill   | University |       |              |     |     |     |     | Graduated | 2009 |\n",
            "| -------- | ---------- | ----- | ------------ | --- | --- | --- | --- | --------- | ---- |\n",
            "| Bachelor | of Science | (BSc) | in Marketing |     |     |     |     |           |      |\n",
            "Skills\n",
            "| Content | Creation | SEO | Social | Media |     |     |     |     |     |\n",
            "| ------- | -------- | --- | ------ | ----- | --- | --- | --- | --- | --- |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ðŸ“„ CV_2.pdf\n",
            "================================================================================\n",
            "| Minh | Pham |     |     |     |     |     |\n",
            "| ---- | ---- | --- | --- | --- | --- | --- |\n",
            "Design Professional\n",
            "| Beijing,     | China | Hong     | Kong     |               |        |              |                |\n",
            "| ------------ | ---------------- | -------- | ------------- | ------ | ------------ | -------------- |\n",
            "| Professional | Experience       |          |               |        |              |                |\n",
            "| Manager,     | BCG              |          |               |        |              | 2022 â€“ Present |\n",
            "| â€¢ Led        | cross-functional | teams on | client-facing | design | initiatives. |                |\n",
            "â€¢ Managed project timelines, deliverables, and stakeholder communication.\n",
            "| â€¢ Applied | design thinking | to business | and | strategy | problems. |             |\n",
            "| --------- | --------------- | ----------- | --- | -------- | --------- | ----------- |\n",
            "| Analyst,  | Tencent         |             |     |          |           | 2013 â€“ 2017 |\n",
            "â€¢ Conducted market and product analysis to support decision-making.\n",
            "| â€¢ Collaborated | with    | design and   | engineering | teams.      |     |     |\n",
            "| -------------- | ------- | ------------ | ----------- | ----------- | --- | --- |\n",
            "| â€¢ Produced     | reports | and insights | for senior  | leadership. |     |     |\n",
            "Education\n",
            "| BSc in         | Design  |      |     |     |     | 2011 |\n",
            "| -------------- | ------- | ---- | --- | --- | --- | ---- |\n",
            "| The University | of Hong | Kong |     |     |     |      |\n",
            "Skills\n",
            "| â€¢ UI/UX | Design |     |     |     |     |     |\n",
            "| ------- | ------ | --- | --- | --- | --- | --- |\n",
            "â€¢ Prototyping\n",
            "| â€¢ Graphic | Design |     |     |     |     |     |\n",
            "| --------- | ------ | --- | --- | --- | --- | --- |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ðŸ“„ CV_3.pdf\n",
            "================================================================================\n",
            "| Wei Zhang    |              |           |     |     |     | Munich, Germany   |\n",
            "| ------------ | ------------ | --------- | --- | --- | --- | ----------------- |\n",
            "| Consulting   | Professional |           |     |     |     | Sydney (Hometown) |\n",
            "| Professional | Experience   |           |     |     |     |                   |\n",
            "| 2013         | â€“ Present    | Engineer, | PwC |     |     |                   |\n",
            "â€¢ Supportedconsultingengagementsacrossmultipleclient\n",
            "projects.\n",
            "|     |     | â€¢ Performed | data analysis | to inform | strategic recommen- |     |\n",
            "| --- | --- | ----------- | ------------- | --------- | ------------------- | --- |\n",
            "dations.\n",
            "|     |     | â€¢ Collaborated  | with         | cross-functional | teams in | a profes- |\n",
            "| --- | --- | --------------- | ------------ | ---------------- | -------- | --------- |\n",
            "|     |     | sional services | environment. |                  |          |           |\n",
            "Education\n",
            "| 2015 |     | BSc in Consulting |          |     |     |     |\n",
            "| ---- | --- | ----------------- | -------- | --- | --- | --- |\n",
            "|      |     | University        | of Tokyo |     |     |     |\n",
            "Skills\n",
            "| Analytical |     |     | Data Analysis,       | Problem | Solving |     |\n",
            "| ---------- | --- | --- | -------------------- | ------- | ------- | --- |\n",
            "| Business   |     |     | Strategy, PowerPoint |         |         |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ðŸ“„ CV_4.pdf\n",
            "================================================================================\n",
            "| Rahul | Sharma |     |     |     |     |     |     |     |     |\n",
            "| ----- | ------ | --- | --- | --- | --- | --- | --- | --- | --- |\n",
            "Legal Professional\n",
            "| Singapore    | (Hometown) | | Singapore              |           | / Philippines |             |        |             |     |         |\n",
            "| ------------ | ---------- | ------------------------ | --------- | ------------- | ----------- | ------ | ----------- | --- | ------- |\n",
            "| Professional |            | Experience               |           |               |             |        |             |     |         |\n",
            "| 2021         | â€“ 2027     | Senior                   | Engineer, | Microsoft     |             |        |             |     |         |\n",
            "|              |            | â€¢ Led compliance-focused |           |               | initiatives | within | large-scale |     | techni- |\n",
            "cal teams.\n",
            "â€¢ Advisedonregulatory,legal,andriskconsiderationsforcom-\n",
            "plex systems.\n",
            "|     |     | â€¢ Worked | at the | intersection |     | of law, | technology, | and | gover- |\n",
            "| --- | --- | -------- | ------ | ------------ | --- | ------- | ----------- | --- | ------ |\n",
            "nance.\n",
            "| 2020 | â€“ 2023 | Consultant, | StartupXYZ |               |     |            |                 |     |      |\n",
            "| ---- | ------ | ----------- | ---------- | ------------- | --- | ---------- | --------------- | --- | ---- |\n",
            "|      |        | â€¢ Provided  | legal      | and strategic |     | consulting | for early-stage |     | com- |\n",
            "panies.\n",
            "|     |     | â€¢ Supported | contract | review, |     | compliance, | and operational |     | risk |\n",
            "| --- | --- | ----------- | -------- | ------- | --- | ----------- | --------------- | --- | ---- |\n",
            "management.\n",
            "|     |     | â€¢ Engaged | with | cross-functional |     | and | international | stakehold- |     |\n",
            "| --- | --- | --------- | ---- | ---------------- | --- | --- | ------------- | ---------- | --- |\n",
            "ers.\n",
            "Education\n",
            "2021\n",
            "|     |     | PhD in   | Legal      | Studies |     |     |     |     |     |\n",
            "| --- | --- | -------- | ---------- | ------- | --- | --- | --- | --- | --- |\n",
            "|     |     | Tsinghua | University |         |     |     |     |     |     |\n",
            "Skills\n",
            "|     |     | Compliance,   | Litigation, |           | Contract | Review    |     |     |     |\n",
            "| --- | --- | ------------- | ----------- | --------- | -------- | --------- | --- | --- | --- |\n",
            "|     |     | Web3, Machine |             | Learning, | Quantum  | Computing |     |     |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ðŸ“„ CV_5.pdf\n",
            "================================================================================\n",
            "| Rahul | Sharma |     |     |     |     |     |     |\n",
            "| ----- | ------ | --- | --- | --- | --- | --- | --- |\n",
            "AI Professional\n",
            "| London     | | Hong Kong | | Singapore | (Hometown) |              |               |                |               |\n",
            "| ---------- | ----------- | ----------- | ---------- | ------------ | ------------- | -------------- | ------------- |\n",
            "| Core       | Skills      |             |            | Professional | Experience    |                |               |\n",
            "| Machine    | Learning    | & AI        |            | Senior       | Engineer      |                |               |\n",
            "|            |             |             |            | EY           |               |                | Current       |\n",
            "| â€¢ Advanced | AI Systems  |             |            |              |               |                |               |\n",
            "|            |             |             |            | â€¢ Designed   | and evaluated | AI-driven      | solutions for |\n",
            "|            |             |             |            | enterprise   | clients.      |                |               |\n",
            "| â€¢ Machine  | Learning    | (ML)        |            |              |               |                |               |\n",
            "|            |             |             |            | â€¢ Applied    | ML techniques | to large-scale | business      |\n",
            "| â€¢ Natural  | Language    | Processing  | (NLP)      | problems.    |               |                |               |\n",
            "Consultant\n",
            "| Frameworks   | &   | Tools |     |             |             |          |             |\n",
            "| ------------ | --- | ----- | --- | ----------- | ----------- | -------- | ----------- |\n",
            "|              |     |       |     | StartupXYZ  |             |          | 2019 â€“ 2021 |\n",
            "| â€¢ TensorFlow |     |       |     | â€¢ Provided  | AI and data | strategy | advisory to |\n",
            "|              |     |       |     | early-stage | companies.  |          |             |\n",
            "â€¢ PyTorch\n",
            "Senior Analyst\n",
            "|     |     |     |     | DataForge |     | 2016 | â€“ Present |\n",
            "| --- | --- | --- | --- | --------- | --- | ---- | --------- |\n",
            "â€¢ Python\n",
            "|     |     |     |     | â€¢ Conducted | advanced | data analysis | and model |\n",
            "| --- | --- | --- | --- | ----------- | -------- | ------------- | --------- |\n",
            "evaluation.\n",
            "Lead Scientist\n",
            "Education\n",
            "|     |     |     |     | UrbanFlow |     |     | 2010 â€“ 2017 |\n",
            "| --- | --- | --- | --- | --------- | --- | --- | ----------- |\n",
            "PhD in Artificial Intelligence â€¢ Led research initiatives in applied AI systems.\n",
            "| University | of Tokyo |     |     |            |                    |                |     |\n",
            "| ---------- | -------- | --- | --- | ---------- | ------------------ | -------------- | --- |\n",
            "| 2012       |          |     |     | â€¢ Mentored | junior researchers | and engineers. |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A simple agent using tools from the MCP server\n"
      ],
      "metadata": {
        "id": "ABoe2-qfXl7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import datetime\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, SystemMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import re\n",
        "import asyncio\n",
        "import json\n",
        "from typing import Dict, Any, List, Optional, Tuple\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "import re\n",
        "import json\n",
        "from typing import Dict, Any, List, Tuple\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "async def verify_cv(cv_text: str, cv_name: str, tools) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Complete CV verification pipeline. Parses CV, searches social media,\n",
        "    cross-checks against LinkedIn/Facebook, and returns scored report.\n",
        "\n",
        "    Args:\n",
        "        cv_text: Raw extracted text from CV PDF\n",
        "        cv_name: CV filename (e.g. \"CV1.pdf\")\n",
        "        tools:   mcptools list from notebook\n",
        "                 tools[0] = searchfacebookusers\n",
        "                 tools[1] = getfacebookprofile\n",
        "                 tools[2] = getfacebookmutualfriends\n",
        "                 tools[3] = searchlinkedinpeople\n",
        "                 tools[4] = getlinkedinprofile\n",
        "                 tools[5] = getlinkedininteractions\n",
        "\n",
        "    Returns:\n",
        "        Dict with score, discrepancies, and evidence\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ðŸ“„ Verifying: {cv_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Step 1: Parse CV\n",
        "\n",
        "    # Step 2: Search & retrieve social profiles (fixed tool calls)\n",
        "    profiles = await search_social_profiles_fixed(\n",
        "        cv_parsed,\n",
        "        tools,\n",
        "        name=cv_parsed.get(\"name\"),\n",
        "        locations=cv_parsed.get(\"locations\"),\n",
        "    )\n",
        "\n",
        "    linkedin_profile = profiles.get(\"linkedin\")\n",
        "    facebook_profile = profiles.get(\"facebook\")\n",
        "\n",
        "    print(\"âœ“ LinkedIn profile:\", \"âœ“ Found\" if linkedin_profile else \"âœ— Not found\")\n",
        "    print(\"âœ“ Facebook profile:\", \"âœ“ Found\" if facebook_profile else \"âœ— Not found\")\n",
        "\n",
        "    if profiles.get(\"errors\"):\n",
        "        print(\"âš ï¸ Search warnings:\", profiles[\"errors\"])\n",
        "\n",
        "    # Step 3: Verification checks\n",
        "    discrepancies: List[Tuple[str, str]] = []\n",
        "\n",
        "    # Check 0: missing profiles\n",
        "    if not linkedin_profile and not facebook_profile and cv_parsed.get(\"name\"):\n",
        "        discrepancies.append((\"MISSING_PROFILES\", \"No social media profiles found for verification\"))\n",
        "        print(\"âš ï¸ No social media profiles found for verification\")\n",
        "\n",
        "    print(\"\\nRunning 6 verification checks...\")\n",
        "\n",
        "    # 1) Name consistency\n",
        "    disc, reason = check_name(cv_parsed.get(\"name\"), linkedin_profile, facebook_profile)\n",
        "    if disc:\n",
        "        discrepancies.append((\"NAME\", reason))\n",
        "        print(f\"âœ— Name: {reason}\")\n",
        "    else:\n",
        "        print(\"âœ“ Name check passed\")\n",
        "\n",
        "    # 2) Location consistency\n",
        "    disc, reason = check_location(cv_parsed.get(\"locations\"), linkedin_profile, facebook_profile)\n",
        "    if disc:\n",
        "        discrepancies.append((\"LOCATION\", reason))\n",
        "        print(f\"âœ— Location: {reason}\")\n",
        "    else:\n",
        "        print(\"âœ“ Location check passed\")\n",
        "\n",
        "    # 3) Education consistency\n",
        "    disc, reason = check_education(cv_parsed.get(\"education\"), linkedin_profile)\n",
        "    if disc:\n",
        "        discrepancies.append((\"EDUCATION\", reason))\n",
        "        print(f\"âœ— Education: {reason}\")\n",
        "    else:\n",
        "        print(\"âœ“ Education check passed\")\n",
        "\n",
        "    # 4) Experience consistency\n",
        "    disc, reason = check_experience(cv_parsed.get(\"companies\"), linkedin_profile)\n",
        "    if disc:\n",
        "        discrepancies.append((\"EXPERIENCE\", reason))\n",
        "        print(f\"âœ— Experience: {reason}\")\n",
        "    else:\n",
        "        print(\"âœ“ Experience check passed\")\n",
        "\n",
        "    # 5) Timeline feasibility\n",
        "    disc, reason = check_timeline(cv_parsed.get(\"years\"), linkedin_profile)\n",
        "    if disc:\n",
        "        discrepancies.append((\"TIMELINE\", reason))\n",
        "        print(f\"âœ— Timeline: {reason}\")\n",
        "    else:\n",
        "        print(\"âœ“ Timeline check passed\")\n",
        "\n",
        "    # Step 4: Score\n",
        "    max_checks = 6  # 5 checks + missing profiles\n",
        "    score = max(0.0, min(1.0, 1.0 - len(discrepancies) / max_checks))\n",
        "\n",
        "    print(\"\\nðŸ“Š Result:\")\n",
        "    print(f\"   Discrepancies found: {len(discrepancies)}/{max_checks}\")\n",
        "    print(f\"   Verification score: {score:.3f}\")\n",
        "\n",
        "    return {\n",
        "        \"cv_name\": cv_name,\n",
        "        \"score\": score,\n",
        "        \"discrepancies\": discrepancies,\n",
        "        \"cv_parsed\": {\n",
        "            \"name\": cv_parsed.get(\"name\"),\n",
        "            \"locations\": cv_parsed.get(\"locations\"),\n",
        "            \"companies\": cv_parsed.get(\"companies\"),\n",
        "            \"skills\": cv_parsed.get(\"skills\"),\n",
        "            \"education\": cv_parsed.get(\"education\"),\n",
        "            \"years\": cv_parsed.get(\"years\"),\n",
        "        },\n",
        "        \"profiles\": profiles,\n",
        "    }\n",
        "\n",
        "# =====================================\n",
        "# Helper functions (all self-contained)\n",
        "# =====================================\n",
        "\n",
        "# ---------------------------\n",
        "# Social search using MCP tools\n",
        "# ---------------------------\n",
        "\n",
        "def similarity_score(a: str, b: str) -> float:\n",
        "    return SequenceMatcher(None, (a or \"\").lower(), (b or \"\").lower()).ratio()\n",
        "\n",
        "async def search_social_profiles_fixed(\n",
        "    cv_info: Dict[str, Any],\n",
        "    tools,\n",
        "    name: str = None,\n",
        "    locations: List[str] = None,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Search LinkedIn + Facebook via mcptools list.\n",
        "    \"\"\"\n",
        "    profiles = {\"linkedin\": None, \"facebook\": None, \"errors\": []}\n",
        "\n",
        "    search_facebook_users_tool = tools[0]\n",
        "    get_facebook_profile_tool = tools[1]\n",
        "    search_linkedin_people_tool = tools[3]\n",
        "    get_linkedin_profile_tool = tools[4]\n",
        "\n",
        "    # LinkedIn Search\n",
        "    try:\n",
        "        li_candidates = await search_linkedin_people_tool.ainvoke({\n",
        "            \"q\": name or \"\",\n",
        "            \"location\": locations[0] if locations else None,\n",
        "            \"industry\": None,\n",
        "            \"limit\": 5,\n",
        "            \"fuzzy\": True\n",
        "        })\n",
        "\n",
        "        if li_candidates and isinstance(li_candidates, list) and len(li_candidates) > 0:\n",
        "            best_li = max(\n",
        "                li_candidates,\n",
        "                key=lambda p: similarity_score(p.get(\"name\", \"\"), name or \"\")\n",
        "            )\n",
        "\n",
        "            raw_id = best_li.get(\"id\")\n",
        "\n",
        "            try:\n",
        "                # If LangChain didn't inject a trace ID, this will safely cast to int\n",
        "                person_id = int(raw_id)\n",
        "            except (ValueError, TypeError):\n",
        "                # If it's a trace ID (\"lc_...\"), we just use it as-is.\n",
        "                # The underlying MCP server might reject it if it strictly wants an int,\n",
        "                # but if LangChain is doing ID mapping behind the scenes, it will resolve it.\n",
        "                person_id = raw_id\n",
        "\n",
        "            try:\n",
        "                # Call the underlying async function directly to bypass LangChain's strict schema validation\n",
        "                li_profile = await get_linkedin_profile_tool.coroutine(personid=person_id)\n",
        "            except TypeError:\n",
        "                 # Some versions of LangChain map the underlying function with a dictionary\n",
        "                li_profile = await get_linkedin_profile_tool.coroutine({\"personid\": person_id})\n",
        "\n",
        "            profiles[\"linkedin\"] = li_profile\n",
        "            print(f\"   âœ“ LinkedIn best match: {best_li.get('name', 'N/A')}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        msg = f\"LinkedIn search failed: {e}\"\n",
        "        profiles[\"errors\"].append(msg)\n",
        "        print(\"   \" + msg)\n",
        "\n",
        "    # Facebook Search\n",
        "    try:\n",
        "        fb_candidates = await search_facebook_users_tool.ainvoke({\n",
        "            \"q\": name or \"\",\n",
        "            \"limit\": 5,\n",
        "            \"fuzzy\": True\n",
        "        })\n",
        "\n",
        "        if fb_candidates and isinstance(fb_candidates, list) and len(fb_candidates) > 0:\n",
        "            best_fb = max(\n",
        "                fb_candidates,\n",
        "                key=lambda p: similarity_score(p.get(\"displayname\", \"\"), name or \"\")\n",
        "            )\n",
        "\n",
        "            raw_id = best_fb.get(\"id\")\n",
        "\n",
        "            try:\n",
        "                user_id = int(raw_id)\n",
        "            except (ValueError, TypeError):\n",
        "                user_id = raw_id\n",
        "\n",
        "            try:\n",
        "                fb_profile = await get_facebook_profile_tool.coroutine(userid=user_id)\n",
        "            except TypeError:\n",
        "                fb_profile = await get_facebook_profile_tool.coroutine({\"userid\": user_id})\n",
        "\n",
        "            profiles[\"facebook\"] = fb_profile\n",
        "            print(f\"   âœ“ Facebook best match: {best_fb.get('displayname', 'N/A')}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        msg = f\"Facebook search failed: {e}\"\n",
        "        profiles[\"errors\"].append(msg)\n",
        "        print(\"   \" + msg)\n",
        "\n",
        "    return profiles\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Consistency checks\n",
        "# ---------------------------\n",
        "\n",
        "def check_name(cv_name: str, li_profile: Dict, fb_profile: Dict) -> Tuple[bool, str]:\n",
        "    if not cv_name:\n",
        "        return False, \"\"\n",
        "    names = []\n",
        "    if li_profile:\n",
        "        names.append(li_profile.get(\"name\", \"\"))\n",
        "    if fb_profile:\n",
        "        names.append(fb_profile.get(\"displayname\", \"\"))\n",
        "        names.append(fb_profile.get(\"originalname\", \"\"))\n",
        "    for soc in names:\n",
        "        if soc and similarity_score(cv_name, soc) > 0.8:\n",
        "            return False, \"\"\n",
        "    return True, f\"CV name '{cv_name}' not found in social profiles\"\n",
        "\n",
        "def check_location(cv_locs: List[str], li_profile: Dict, fb_profile: Dict) -> Tuple[bool, str]:\n",
        "    if not cv_locs:\n",
        "        return False, \"\"\n",
        "    soc_locs = []\n",
        "    if li_profile:\n",
        "        soc_locs.append(f\"{li_profile.get('city', '')} {li_profile.get('country', '')}\".lower())\n",
        "    if fb_profile:\n",
        "        soc_locs.append((fb_profile.get(\"city\") or \"\").lower())\n",
        "        soc_locs.append((fb_profile.get(\"country\") or \"\").lower())\n",
        "    cv_set = set(cv_locs)\n",
        "    for sl in soc_locs:\n",
        "        if any(loc in sl for loc in cv_set):\n",
        "            return False, \"\"\n",
        "    return True, f\"CV locations {cv_locs} not found in social profiles\"\n",
        "\n",
        "def check_education(cv_edu: List[str], li_profile: Dict) -> Tuple[bool, str]:\n",
        "    if not cv_edu or not li_profile:\n",
        "        return False, \"\"\n",
        "    liedu = [\n",
        "        (e.get(\"school\", \"\") + \" \" + e.get(\"degree\", \"\")).lower()\n",
        "        for e in li_profile.get(\"education\", [])\n",
        "    ]\n",
        "    for edu in cv_edu:\n",
        "        if any(edu in le for le in liedu):\n",
        "            return False, \"\"\n",
        "    return True, f\"CV education {cv_edu} not found in LinkedIn\"\n",
        "\n",
        "def check_experience(cv_companies: List[str], li_profile: Dict) -> Tuple[bool, str]:\n",
        "    if not cv_companies or not li_profile:\n",
        "        return False, \"\"\n",
        "    licompanies = [e.get(\"company\", \"\").lower() for e in li_profile.get(\"experience\", [])]\n",
        "    found = any(comp.lower() in \" \".join(licompanies) for comp in cv_companies)\n",
        "    return (not found, f\"CV companies {cv_companies} not found in LinkedIn experience\")\n",
        "\n",
        "def check_timeline(cv_years: List[int], li_profile: Dict) -> Tuple[bool, str]:\n",
        "    if not cv_years:\n",
        "        return False, \"\"\n",
        "    cv_min, cv_max = min(cv_years), max(cv_years)\n",
        "\n",
        "    if cv_max > 2026 or cv_min < 1950 or cv_max < cv_min:\n",
        "        return True, f\"Impossible timeline: {cv_min}-{cv_max}\"\n",
        "\n",
        "    if li_profile:\n",
        "        li_years = li_profile.get(\"yearsexperience\", 0)\n",
        "        if li_years and abs(li_years - (cv_max - cv_min)) > 10:\n",
        "            return True, f\"Timeline mismatch: CV {cv_max - cv_min}y vs LinkedIn {li_years}y\"\n",
        "\n",
        "    return False, \"\"\n",
        "\n",
        "# ---------------------------\n",
        "# Main verify function\n",
        "# ---------------------------\n",
        "\n",
        "async def verify_cv(cv_text: str, cv_name: str, tools, cv_index: int = 0) -> Dict[str, Any]:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ðŸ“„ Verifying: {cv_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # ==========================================\n",
        "    # Step 1: Agentic CV Parsing\n",
        "    # ==========================================\n",
        "    # Use the LLM to parse the CV instead of regex\n",
        "    parse_prompt = f\"\"\"\n",
        "    You are a CV parser. Please read the following CV text and extract key information.\n",
        "    Return ONLY a valid JSON object with exactly these keys:\n",
        "    - \"name\": (string) the person's full name\n",
        "    - \"locations\": (list of strings) cities/countries mentioned\n",
        "    - \"companies\": (list of strings) companies they worked for\n",
        "    - \"education\": (list of strings) degrees or university names\n",
        "    - \"skills\": (list of strings) professional skills\n",
        "    - \"years\": (list of integers) any 4-digit years mentioned (e.g., 2020, 2024)\n",
        "\n",
        "    CV Text:\n",
        "    {cv_text}\n",
        "    \"\"\"\n",
        "\n",
        "    # We use Gemini directly here to act as our parser\n",
        "    parse_response = await llm.ainvoke([HumanMessage(content=parse_prompt)])\n",
        "\n",
        "    # Clean up the JSON response\n",
        "    clean_json = parse_response.content.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "    try:\n",
        "        cv_parsed = json.loads(clean_json)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"âš ï¸ Warning: LLM failed to return valid JSON. Falling back to empty dict.\")\n",
        "        cv_parsed = {\n",
        "            \"name\": \"\", \"locations\": [], \"companies\": [],\n",
        "            \"education\": [], \"skills\": [], \"years\": []\n",
        "        }\n",
        "\n",
        "    print(\"âœ“ Name extracted:\", cv_parsed.get(\"name\", \"N/A\"))\n",
        "    print(\"âœ“ Locations found:\", cv_parsed.get(\"locations\", \"N/A\"))\n",
        "    print(\"âœ“ Companies found:\", cv_parsed.get(\"companies\", \"N/A\"))\n",
        "    print(\n",
        "        \"âœ“ Year range:\",\n",
        "        f\"{min(cv_parsed.get('years', []))} - {max(cv_parsed.get('years', []))}\"\n",
        "        if cv_parsed.get(\"years\") else \"N/A\"\n",
        "    )\n",
        "\n",
        "    # ==========================================\n",
        "    # Step 2: Search Social Profiles\n",
        "    # ==========================================\n",
        "    profiles = await search_social_profiles_fixed(\n",
        "        cv_parsed,\n",
        "        tools,\n",
        "        name=cv_parsed.get(\"name\"),\n",
        "        locations=cv_parsed.get(\"locations\"),\n",
        "    )\n",
        "\n",
        "    linkedin_profile = profiles.get(\"linkedin\")\n",
        "    facebook_profile = profiles.get(\"facebook\")\n",
        "\n",
        "    print(\"âœ“ LinkedIn profile:\", \"âœ“ Found\" if linkedin_profile else \"âœ— Not found\")\n",
        "    print(\"âœ“ Facebook profile:\", \"âœ“ Found\" if facebook_profile else \"âœ— Not found\")\n",
        "\n",
        "    if profiles.get(\"errors\"):\n",
        "        print(\"âš ï¸ Search warnings:\", profiles[\"errors\"])\n",
        "\n",
        "    # ==========================================\n",
        "    # Step 3: Verification Checks\n",
        "    # ==========================================\n",
        "    discrepancies: List[Tuple[str, str]] = []\n",
        "\n",
        "    if not linkedin_profile and not facebook_profile and cv_parsed.get(\"name\"):\n",
        "        discrepancies.append((\"MISSING_PROFILES\", \"No social media profiles found for verification\"))\n",
        "        print(\"âš ï¸ No social media profiles found for verification\")\n",
        "\n",
        "    print(\"\\nRunning 6 verification checks...\")\n",
        "\n",
        "    disc, reason = check_name(cv_parsed.get(\"name\"), linkedin_profile, facebook_profile)\n",
        "    if disc:\n",
        "        discrepancies.append((\"NAME\", reason))\n",
        "        print(f\"âœ— Name: {reason}\")\n",
        "    else:\n",
        "        print(\"âœ“ Name check passed\")\n",
        "\n",
        "    disc, reason = check_location(cv_parsed.get(\"locations\"), linkedin_profile, facebook_profile)\n",
        "    if disc:\n",
        "        discrepancies.append((\"LOCATION\", reason))\n",
        "        print(f\"âœ— Location: {reason}\")\n",
        "    else:\n",
        "        print(\"âœ“ Location check passed\")\n",
        "\n",
        "    disc, reason = check_education(cv_parsed.get(\"education\"), linkedin_profile)\n",
        "    if disc:\n",
        "        discrepancies.append((\"EDUCATION\", reason))\n",
        "        print(f\"âœ— Education: {reason}\")\n",
        "    else:\n",
        "        print(\"âœ“ Education check passed\")\n",
        "\n",
        "    disc, reason = check_experience(cv_parsed.get(\"companies\"), linkedin_profile)\n",
        "    if disc:\n",
        "        discrepancies.append((\"EXPERIENCE\", reason))\n",
        "        print(f\"âœ— Experience: {reason}\")\n",
        "    else:\n",
        "        print(\"âœ“ Experience check passed\")\n",
        "\n",
        "    disc, reason = check_timeline(cv_parsed.get(\"years\"), linkedin_profile)\n",
        "    if disc:\n",
        "        discrepancies.append((\"TIMELINE\", reason))\n",
        "        print(f\"âœ— Timeline: {reason}\")\n",
        "    else:\n",
        "        print(\"âœ“ Timeline check passed\")\n",
        "\n",
        "    # ==========================================\n",
        "    # Step 4: Scoring\n",
        "    # ==========================================\n",
        "    max_checks = 6\n",
        "    score = max(0.0, min(1.0, 1.0 - len(discrepancies) / max_checks))\n",
        "\n",
        "    print(\"\\nðŸ“Š Result:\")\n",
        "    print(f\"   Discrepancies found: {len(discrepancies)}/{max_checks}\")\n",
        "    print(f\"   Verification score: {score:.3f}\")\n",
        "\n",
        "    return {\n",
        "        \"cv_name\": cv_name,\n",
        "        \"score\": score,\n",
        "        \"discrepancies\": discrepancies,\n",
        "        \"cv_parsed\": cv_parsed,\n",
        "        \"profiles\": profiles,\n",
        "    }\n",
        "\n",
        "\n",
        "# # ---------------------------\n",
        "# # 1. Define local tools\n",
        "# # ---------------------------\n",
        "@tool\n",
        "def say_hello(name: str) -> str:\n",
        "    \"\"\"Say hello to a person by name.\"\"\"\n",
        "    return f\"Hello, {name}! ðŸ‘‹\"\n",
        "\n",
        "@tool\n",
        "async def verify_cv_tool(cv_index: int) -> str:\n",
        "    \"\"\"\n",
        "    Verify a single CV by its 0-based index in the `all_cvs` global list.\n",
        "    Parses the CV text, searches social media for inconsistencies, and returns a detailed report.\n",
        "\n",
        "    Args:\n",
        "        cv_index: The 0-based index of the CV to verify. For example, use `0` for CV_1.pdf, `1` for CV_2.pdf, etc.\n",
        "    Returns:\n",
        "        A JSON string of the verification report including score and discrepancies.\n",
        "    \"\"\"\n",
        "    if not (0 <= cv_index < len(all_cvs)):\n",
        "        return json.dumps({\"error\": f\"Invalid CV index: {cv_index}. Must be between 0 and {len(all_cvs) - 1}.\"})\n",
        "\n",
        "    cv_data = all_cvs[cv_index]\n",
        "    cv_file = cv_data[\"file\"]\n",
        "    cv_text = cv_data[\"text\"]\n",
        "\n",
        "    try:\n",
        "        report = await verify_cv(cv_text, cv_file, tools) # Calls the working verify_cv function\n",
        "        return json.dumps(report, indent=2)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Failed to verify CV {cv_file}: {str(e)}\"}) # Provide error message\n",
        "\n",
        "@tool\n",
        "def get_cv_text(cv_index: int) -> str:\n",
        "    \"\"\"\n",
        "    Retrieve the parsed text of a CV by its index (0 to 4).\n",
        "    Use index 0 for CV1.pdf, index 1 for CV2.pdf, etc.\n",
        "    Returns a JSON string containing the filename and raw text.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        idx = int(cv_index)\n",
        "        if 0 <= idx < len(all_cvs):\n",
        "            return json.dumps(all_cvs[idx])\n",
        "        return json.dumps({\"error\": f\"Invalid index. Must be 0 to {len(all_cvs)-1}\"})\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": str(e)})\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Load MCP tools + merge\n",
        "# ---------------------------\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "# mcp_tools is assumed to be globally available from cell 6h0311KbN9A3\n",
        "# tools = mcp_tools + [verify_cv_tool]\n",
        "tools = mcp_tools + [say_hello, verify_cv_tool, get_cv_text] # Add the new verify_cv_tool\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Initialize Gemini (tool-enabled)\n",
        "# ---------------------------\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    google_api_key=GEMINI_VERTEX_API_KEY,\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# The single-step invocation example is removed from here as the main demonstration\n",
        "# will be in cell I8ifMpsVh6IQ for the conversational agent."
      ],
      "metadata": {
        "id": "jtTjwFKhTKn3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This block provides you some tests to get faminilar with our MCP server\n",
        "\n",
        "# Test 1: Search Facebook users (exact match)\n",
        "# await tools[0].ainvoke({'q': \"Alice\", 'limit': 5})\n",
        "\n",
        "# # Test 2: Search Facebook users (fuzzy match with typo)\n",
        "# await tools[0].ainvoke({'q': \"Alx Chn\", 'limit': 5, 'fuzzy': True})\n",
        "\n",
        "# Test 3: Get Facebook profile\n",
        "# await tools[1].ainvoke({'user_id': 123})\n",
        "\n",
        "# # Test 4: Get Facebook mutual friends\n",
        "# await tools[2].ainvoke({'user_id_1': 123, 'user_id_2': 456})\n",
        "\n",
        "# # Test 5: Search LinkedIn people (exact match)\n",
        "# await tools[3].ainvoke({'q': \"Python\", 'location': \"Hong Kong\", 'limit': 5})\n",
        "\n",
        "# # Test 6: Search LinkedIn people (fuzzy match with typo)\n",
        "# await tools[3].ainvoke({'q': \"Python\", 'location': \"Hong Kong\", 'limit': 5, 'fuzzy': True})\n",
        "\n",
        "# Test 7: Get LinkedIn profile\n",
        "# await tools[4].ainvoke({'person_id': 456})\n",
        "\n",
        "# # Test 8: Get LinkedIn interactions\n",
        "# await tools[5].ainvoke({'person_id': 456})"
      ],
      "metadata": {
        "id": "AhLeoXGrqesW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT =  \"\"\"\n",
        "You are an autonomous AI assistant for automated CV verification.\n",
        "\n",
        "Goal:\n",
        "1. Fetch a candidate's CV text using the `get_cv_text` tool.\n",
        "2. Read and parse the CV text internally to extract: Name, Location, Companies, Education, and Timeline (years).\n",
        "3. Search LinkedIn (`searchlinkedinpeople`) using the extracted Name and Location.\n",
        "4. If a LinkedIn match is found, extract its `id` and get the full profile using `getlinkedinprofile`.\n",
        "5. Search Facebook (`searchfacebookusers`) using the extracted Name.\n",
        "6. If a Facebook match is found, extract its `id` and get the full profile using `getfacebookprofile`.\n",
        "7. Cross-check the CV claims against the retrieved social profiles.\n",
        "8. Output a strictly formatted JSON verification report.\n",
        "\n",
        "Available Tools:\n",
        "- get_cv_text(cv_index)\n",
        "- searchfacebookusers(q, limit, fuzzy)\n",
        "- getfacebookprofile(userid)\n",
        "- searchlinkedinpeople(q, location, industry, limit, fuzzy)\n",
        "- getlinkedinprofile(personid)\n",
        "- getlinkedininteractions(personid)\n",
        "\n",
        "Important Rules for Tool Calling:\n",
        "- When calling `getlinkedinprofile`, pass the argument exactly as `personid`.\n",
        "- When calling `getfacebookprofile`, pass the argument exactly as `userid`.\n",
        "- If multiple profiles are returned from a search, choose the best match based on name and location.\n",
        "- If a search returns no results, do not make up fake profiles. State that it was not found.\n",
        "\n",
        "Output Format:\n",
        "Your final output MUST be a single JSON block formatted exactly like this:\n",
        "{\n",
        "  \"cv_name\": \"CV1.pdf\",\n",
        "  \"overall_score\": 0.0,\n",
        "  \"evidence\": {\n",
        "    \"cv_summary\": { ... },\n",
        "    \"linkedin\": { ... },\n",
        "    \"facebook\": { ... }\n",
        "  },\n",
        "  \"checks\": { ... },\n",
        "  \"discrepancies\": [ ... ]\n",
        "}\n",
        "\n",
        "Scoring:\n",
        "Start at 1.0. Subtract 0.25 for High severity discrepancies, 0.15 for Medium, and 0.05 for Low. Floor at 0.0.\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "goRNjhhkc-Do"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def agent_verify(cv_index: int) -> str:\n",
        "    \"\"\"Run the conversational agent to verify a single CV.\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ðŸ¤– Starting Agent Verification for CV {cv_index+1}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    messages = [\n",
        "        SystemMessage(content=SYSTEM_PROMPT),\n",
        "        HumanMessage(content=f\"Fetch and verify CV at index {cv_index}. Output the final JSON report.\")\n",
        "    ]\n",
        "\n",
        "    max_iterations = 10\n",
        "\n",
        "    for i in range(max_iterations):\n",
        "        response = await llm_with_tools.ainvoke(messages)\n",
        "        messages.append(response)\n",
        "\n",
        "        # If the LLM didn't call tools, it's done (returning the final JSON)\n",
        "        if not response.tool_calls:\n",
        "            print(f\"âœ… Final Agent Output received.\\n\")\n",
        "            return response.content\n",
        "\n",
        "        # Execute requested tools\n",
        "        for tool_call in response.tool_calls:\n",
        "            tool_name = tool_call[\"name\"]\n",
        "            tool_args = tool_call[\"args\"]\n",
        "            print(f\"ðŸ”§ Agent calling tool: {tool_name}\")\n",
        "            # print(f\"   Args: {tool_args}\")\n",
        "\n",
        "            # Find the actual tool object\n",
        "            tool_obj = next((t for t in tools if t.name == tool_name), None)\n",
        "\n",
        "            if tool_obj:\n",
        "                try:\n",
        "                    # LangChain handles the dict injection correctly here\n",
        "                    result = await tool_obj.ainvoke(tool_args)\n",
        "                    messages.append(ToolMessage(content=str(result), tool_call_id=tool_call[\"id\"]))\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ Error in {tool_name}: {e}\")\n",
        "                    messages.append(ToolMessage(content=f\"Error: {str(e)}\", tool_call_id=tool_call[\"id\"]))\n",
        "            else:\n",
        "                messages.append(ToolMessage(content=f\"Tool {tool_name} not found.\", tool_call_id=tool_call[\"id\"]))\n",
        "\n",
        "    return \"Agent reached max iterations without completing.\""
      ],
      "metadata": {
        "id": "I8ifMpsVh6IQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5571895",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf5d78bc-acbe-4fd0-d620-9fb6fc7da201"
      },
      "source": [
        "async def process_all_cvs(all_cvs, tools):\n",
        "    scores, results = [], []\n",
        "    for i, cv in enumerate(all_cvs):\n",
        "        # We pass cv_index=i just in case you need it later, though the text is passed directly\n",
        "        res = await verify_cv(cv[\"text\"], cv[\"file\"], tools, cv_index=i)\n",
        "        results.append(res)\n",
        "        scores.append(res[\"score\"])\n",
        "    return scores, results\n",
        "\n",
        "# Example execution:\n",
        "final_scores, results = await process_all_cvs(all_cvs, tools)\n",
        "print(\"Final Scores:\", final_scores)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ðŸ“„ Verifying: CV_1.pdf\n",
            "============================================================\n",
            "âœ“ Name extracted: John Smith\n",
            "âœ“ Locations found: ['Singapore', 'Kowloon']\n",
            "âœ“ Companies found: ['ByteDance']\n",
            "âœ“ Year range: 2009 - 2020\n",
            "   LinkedIn search failed: 2 validation errors for call[get_linkedin_profile]\n",
            "person_id\n",
            "  Missing required argument [type=missing_argument, input_value={'personid': 'lc_d1c32504...42f3-95a2-87ac8b5a4d6e'}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\n",
            "personid\n",
            "  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_d1c32504-12c7-42f3-95a2-87ac8b5a4d6e', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\n",
            "   Facebook search failed: 2 validation errors for call[get_facebook_profile]\n",
            "user_id\n",
            "  Missing required argument [type=missing_argument, input_value={'userid': 'lc_43f2f5db-c...40b5-9662-ca517b491e30'}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\n",
            "userid\n",
            "  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_43f2f5db-c161-40b5-9662-ca517b491e30', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\n",
            "âœ“ LinkedIn profile: âœ— Not found\n",
            "âœ“ Facebook profile: âœ— Not found\n",
            "âš ï¸ Search warnings: [\"LinkedIn search failed: 2 validation errors for call[get_linkedin_profile]\\nperson_id\\n  Missing required argument [type=missing_argument, input_value={'personid': 'lc_d1c32504...42f3-95a2-87ac8b5a4d6e'}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\\npersonid\\n  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_d1c32504-12c7-42f3-95a2-87ac8b5a4d6e', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\", \"Facebook search failed: 2 validation errors for call[get_facebook_profile]\\nuser_id\\n  Missing required argument [type=missing_argument, input_value={'userid': 'lc_43f2f5db-c...40b5-9662-ca517b491e30'}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\\nuserid\\n  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_43f2f5db-c161-40b5-9662-ca517b491e30', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\"]\n",
            "âš ï¸ No social media profiles found for verification\n",
            "\n",
            "Running 6 verification checks...\n",
            "âœ— Name: CV name 'John Smith' not found in social profiles\n",
            "âœ— Location: CV locations ['Singapore', 'Kowloon'] not found in social profiles\n",
            "âœ“ Education check passed\n",
            "âœ“ Experience check passed\n",
            "âœ“ Timeline check passed\n",
            "\n",
            "ðŸ“Š Result:\n",
            "   Discrepancies found: 3/6\n",
            "   Verification score: 0.500\n",
            "\n",
            "============================================================\n",
            "ðŸ“„ Verifying: CV_2.pdf\n",
            "============================================================\n",
            "âœ“ Name extracted: Minh Pham\n",
            "âœ“ Locations found: ['Beijing', 'China', 'Hong Kong']\n",
            "âœ“ Companies found: ['BCG', 'Tencent']\n",
            "âœ“ Year range: 2011 - 2022\n",
            "   LinkedIn search failed: 2 validation errors for call[get_linkedin_profile]\n",
            "person_id\n",
            "  Missing required argument [type=missing_argument, input_value={'personid': 'lc_72884da3...4208-8a87-fb85d7917f82'}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\n",
            "personid\n",
            "  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_72884da3-6193-4208-8a87-fb85d7917f82', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\n",
            "   Facebook search failed: 2 validation errors for call[get_facebook_profile]\n",
            "user_id\n",
            "  Missing required argument [type=missing_argument, input_value={'userid': 'lc_0344559e-2...4a29-a5db-c8034c98c39c'}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\n",
            "userid\n",
            "  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_0344559e-2e50-4a29-a5db-c8034c98c39c', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\n",
            "âœ“ LinkedIn profile: âœ— Not found\n",
            "âœ“ Facebook profile: âœ— Not found\n",
            "âš ï¸ Search warnings: [\"LinkedIn search failed: 2 validation errors for call[get_linkedin_profile]\\nperson_id\\n  Missing required argument [type=missing_argument, input_value={'personid': 'lc_72884da3...4208-8a87-fb85d7917f82'}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\\npersonid\\n  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_72884da3-6193-4208-8a87-fb85d7917f82', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\", \"Facebook search failed: 2 validation errors for call[get_facebook_profile]\\nuser_id\\n  Missing required argument [type=missing_argument, input_value={'userid': 'lc_0344559e-2...4a29-a5db-c8034c98c39c'}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\\nuserid\\n  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_0344559e-2e50-4a29-a5db-c8034c98c39c', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\"]\n",
            "âš ï¸ No social media profiles found for verification\n",
            "\n",
            "Running 6 verification checks...\n",
            "âœ— Name: CV name 'Minh Pham' not found in social profiles\n",
            "âœ— Location: CV locations ['Beijing', 'China', 'Hong Kong'] not found in social profiles\n",
            "âœ“ Education check passed\n",
            "âœ“ Experience check passed\n",
            "âœ“ Timeline check passed\n",
            "\n",
            "ðŸ“Š Result:\n",
            "   Discrepancies found: 3/6\n",
            "   Verification score: 0.500\n",
            "\n",
            "============================================================\n",
            "ðŸ“„ Verifying: CV_3.pdf\n",
            "============================================================\n",
            "âœ“ Name extracted: Wei Zhang\n",
            "âœ“ Locations found: ['Munich, Germany', 'Sydney']\n",
            "âœ“ Companies found: ['PwC']\n",
            "âœ“ Year range: 2013 - 2015\n",
            "   Facebook search failed: 2 validation errors for call[get_facebook_profile]\n",
            "user_id\n",
            "  Missing required argument [type=missing_argument, input_value={'userid': 'lc_283c787a-a...4d2d-932f-0b7ff530dc59'}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\n",
            "userid\n",
            "  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_283c787a-ac3e-4d2d-932f-0b7ff530dc59', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\n",
            "âœ“ LinkedIn profile: âœ— Not found\n",
            "âœ“ Facebook profile: âœ— Not found\n",
            "âš ï¸ Search warnings: [\"Facebook search failed: 2 validation errors for call[get_facebook_profile]\\nuser_id\\n  Missing required argument [type=missing_argument, input_value={'userid': 'lc_283c787a-a...4d2d-932f-0b7ff530dc59'}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\\nuserid\\n  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_283c787a-ac3e-4d2d-932f-0b7ff530dc59', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\"]\n",
            "âš ï¸ No social media profiles found for verification\n",
            "\n",
            "Running 6 verification checks...\n",
            "âœ— Name: CV name 'Wei Zhang' not found in social profiles\n",
            "âœ— Location: CV locations ['Munich, Germany', 'Sydney'] not found in social profiles\n",
            "âœ“ Education check passed\n",
            "âœ“ Experience check passed\n",
            "âœ“ Timeline check passed\n",
            "\n",
            "ðŸ“Š Result:\n",
            "   Discrepancies found: 3/6\n",
            "   Verification score: 0.500\n",
            "\n",
            "============================================================\n",
            "ðŸ“„ Verifying: CV_4.pdf\n",
            "============================================================\n",
            "âœ“ Name extracted: Rahul Sharma\n",
            "âœ“ Locations found: ['Singapore', 'Philippines']\n",
            "âœ“ Companies found: ['Microsoft', 'StartupXYZ']\n",
            "âœ“ Year range: 2020 - 2027\n",
            "   LinkedIn search failed: 2 validation errors for call[get_linkedin_profile]\n",
            "person_id\n",
            "  Missing required argument [type=missing_argument, input_value={'personid': 'lc_ab9d3329...47b8-bfa3-8ed60e5647bb'}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\n",
            "personid\n",
            "  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_ab9d3329-9562-47b8-bfa3-8ed60e5647bb', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\n",
            "   Facebook search failed: 2 validation errors for call[get_facebook_profile]\n",
            "user_id\n",
            "  Missing required argument [type=missing_argument, input_value={'userid': 'lc_d80b5201-9...45d1-b545-9b192b577042'}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\n",
            "userid\n",
            "  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_d80b5201-97fa-45d1-b545-9b192b577042', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\n",
            "âœ“ LinkedIn profile: âœ— Not found\n",
            "âœ“ Facebook profile: âœ— Not found\n",
            "âš ï¸ Search warnings: [\"LinkedIn search failed: 2 validation errors for call[get_linkedin_profile]\\nperson_id\\n  Missing required argument [type=missing_argument, input_value={'personid': 'lc_ab9d3329...47b8-bfa3-8ed60e5647bb'}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\\npersonid\\n  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_ab9d3329-9562-47b8-bfa3-8ed60e5647bb', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\", \"Facebook search failed: 2 validation errors for call[get_facebook_profile]\\nuser_id\\n  Missing required argument [type=missing_argument, input_value={'userid': 'lc_d80b5201-9...45d1-b545-9b192b577042'}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\\nuserid\\n  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_d80b5201-97fa-45d1-b545-9b192b577042', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\"]\n",
            "âš ï¸ No social media profiles found for verification\n",
            "\n",
            "Running 6 verification checks...\n",
            "âœ— Name: CV name 'Rahul Sharma' not found in social profiles\n",
            "âœ— Location: CV locations ['Singapore', 'Philippines'] not found in social profiles\n",
            "âœ“ Education check passed\n",
            "âœ“ Experience check passed\n",
            "âœ— Timeline: Impossible timeline: 2020-2027\n",
            "\n",
            "ðŸ“Š Result:\n",
            "   Discrepancies found: 4/6\n",
            "   Verification score: 0.333\n",
            "\n",
            "============================================================\n",
            "ðŸ“„ Verifying: CV_5.pdf\n",
            "============================================================\n",
            "âœ“ Name extracted: Rahul Sharma\n",
            "âœ“ Locations found: ['London', 'Hong Kong', 'Singapore', 'Tokyo']\n",
            "âœ“ Companies found: ['EY', 'StartupXYZ', 'DataForge', 'UrbanFlow']\n",
            "âœ“ Year range: 2010 - 2021\n",
            "   LinkedIn search failed: 2 validation errors for call[get_linkedin_profile]\n",
            "person_id\n",
            "  Missing required argument [type=missing_argument, input_value={'personid': 'lc_092a8f41...4c4c-8052-5b40aa5a8c13'}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\n",
            "personid\n",
            "  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_092a8f41-6a5d-4c4c-8052-5b40aa5a8c13', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\n",
            "   Facebook search failed: 2 validation errors for call[get_facebook_profile]\n",
            "user_id\n",
            "  Missing required argument [type=missing_argument, input_value={'userid': 'lc_87bd74ad-9...427c-947a-43de11e3960f'}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\n",
            "userid\n",
            "  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_87bd74ad-9dc3-427c-947a-43de11e3960f', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\n",
            "âœ“ LinkedIn profile: âœ— Not found\n",
            "âœ“ Facebook profile: âœ— Not found\n",
            "âš ï¸ Search warnings: [\"LinkedIn search failed: 2 validation errors for call[get_linkedin_profile]\\nperson_id\\n  Missing required argument [type=missing_argument, input_value={'personid': 'lc_092a8f41...4c4c-8052-5b40aa5a8c13'}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\\npersonid\\n  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_092a8f41-6a5d-4c4c-8052-5b40aa5a8c13', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\", \"Facebook search failed: 2 validation errors for call[get_facebook_profile]\\nuser_id\\n  Missing required argument [type=missing_argument, input_value={'userid': 'lc_87bd74ad-9...427c-947a-43de11e3960f'}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.12/v/missing_argument\\nuserid\\n  Unexpected keyword argument [type=unexpected_keyword_argument, input_value='lc_87bd74ad-9dc3-427c-947a-43de11e3960f', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/unexpected_keyword_argument\"]\n",
            "âš ï¸ No social media profiles found for verification\n",
            "\n",
            "Running 6 verification checks...\n",
            "âœ— Name: CV name 'Rahul Sharma' not found in social profiles\n",
            "âœ— Location: CV locations ['London', 'Hong Kong', 'Singapore', 'Tokyo'] not found in social profiles\n",
            "âœ“ Education check passed\n",
            "âœ“ Experience check passed\n",
            "âœ“ Timeline check passed\n",
            "\n",
            "ðŸ“Š Result:\n",
            "   Discrepancies found: 3/6\n",
            "   Verification score: 0.500\n",
            "Final Scores: [0.5, 0.5, 0.5, 0.33333333333333337, 0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation code\n",
        "\n",
        "In the test phase, you will be given 5 CV files with fixed names:\n",
        "\n",
        "    CV_1.pdf, CV_2.pdf, CV_3.pdf, CV_4.pdf, CV_5.pdf\n",
        "\n",
        "Your system must process these CVs and output a list of 5 scores,\n",
        "one score per CV, in the same order:\n",
        "\n",
        "    scores = [s1, s2, s3, s4, s5]\n",
        "\n",
        "Each score must be a float in the range [0, 1], representing the\n",
        "reliability or confidence that the CV is valid (or meets the task criteria).\n",
        "\n",
        "The ground-truth labels are binary:\n",
        "\n",
        "    groundtruth = [0 or 1, ..., 0 or 1]\n",
        "\n",
        "Each CV is evaluated independently using a threshold of 0.5:\n",
        "\n",
        "- If score > 0.5 and groundtruth == 1 â†’ Full credit\n",
        "- If score â‰¤ 0.5 and groundtruth == 0 â†’ Full credit\n",
        "- Otherwise â†’ No credit\n",
        "\n",
        "In other words, 0.5 is the decision threshold.\n",
        "\n",
        "- Each CV contributes equally.\n",
        "- Final score = (number of correct decisions) / 5\n"
      ],
      "metadata": {
        "id": "UqO99iOlq6mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "#  Evaluation code\n",
        "# =====================================================\n",
        "\n",
        "def evaluate(scores, groundtruth, threshold=0.5):\n",
        "    \"\"\"\n",
        "    scores: list of floats in [0, 1], length = 5\n",
        "    groundtruth: list of ints (0 or 1), length = 5\n",
        "    \"\"\"\n",
        "    assert len(scores) == 5\n",
        "    assert len(groundtruth) == 5\n",
        "\n",
        "    correct = 0\n",
        "    decisions = []\n",
        "\n",
        "    for s, gt in zip(scores, groundtruth):\n",
        "        pred = 1 if s > threshold else 0\n",
        "        decisions.append(pred)\n",
        "        if pred == gt:\n",
        "            correct += 1\n",
        "\n",
        "    final_score = correct / len(scores)\n",
        "\n",
        "    return {\n",
        "        \"decisions\": decisions,\n",
        "        \"correct\": correct,\n",
        "        \"total\": len(scores),\n",
        "        \"final_score\": final_score\n",
        "    }\n"
      ],
      "metadata": {
        "id": "0TtL07airIqz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = final_scores\n",
        "groundtruth = [1, 1, 1, 0, 0] # Do not modify\n",
        "\n",
        "result = evaluate(scores, groundtruth)\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "J14ltXjPtaMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea4f4b14-ad5f-4bbb-cd6c-bdc289a9f7c5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'decisions': [0, 0, 0, 0, 0], 'correct': 2, 'total': 5, 'final_score': 0.4}\n"
          ]
        }
      ]
    }
  ]
}